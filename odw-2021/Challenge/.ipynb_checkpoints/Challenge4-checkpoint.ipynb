{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "A_sq7ix-63lJ"
   },
   "outputs": [],
   "source": [
    "from gwpy.timeseries import TimeSeries\n",
    "data1= TimeSeries.read('challenge3.gwf', 'H1:CHALLENGE3')\n",
    "data2=TimeSeries.read('challenge3.gwf', 'L1:CHALLENGE3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "OXUdKlSY7-MQ"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "signal1=np.array(data1)\n",
    "signal2=np.array(data2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 592
    },
    "colab_type": "code",
    "id": "G2kWX8xu8NuM",
    "outputId": "c82ba15a-d0b5-4279-c9f9-697b7a021de5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duration_H1: 4096.0s delta_t_H1: 0.000244140625s sampling rate_H1: 4096.0Hz Start_H1: 0 End_H1: 4096\n",
      "Duration_L1: 4096.0s delta_t_L1: 0.000244140625s sampling rate_L1: 4096.0Hz Start_L1: 0 End_L1: 4096\n"
     ]
    }
   ],
   "source": [
    "from pycbc.frame import read_frame\n",
    "\n",
    "ts_H1 = read_frame(\"challenge3.gwf\", \"H1:CHALLENGE3\")\n",
    "\n",
    "print(\"Duration_H1: {}s delta_t_H1: {}s sampling rate_H1: {}Hz Start_H1: {} End_H1: {}\".format(ts_H1.duration, ts_H1.delta_t, 1/ts_H1.delta_t,\n",
    "                                              int(ts_H1.start_time),\n",
    "                                              int(ts_H1.end_time)))\n",
    "\n",
    "ts_L1 = read_frame(\"challenge3.gwf\", \"L1:CHALLENGE3\")\n",
    "\n",
    "print(\"Duration_L1: {}s delta_t_L1: {}s sampling rate_L1: {}Hz Start_L1: {} End_L1: {}\".format(ts_L1.duration, ts_L1.delta_t, 1/ts_L1.delta_t,\n",
    "                                              int(ts_L1.start_time),\n",
    "                                              int(ts_L1.end_time)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pycbc.filter import resample_to_delta_t, highpass\n",
    "from pycbc.catalog import Merger\n",
    "from pycbc.psd import interpolate, inverse_spectrum_truncation\n",
    "\n",
    "data_H1 = resample_to_delta_t(ts_H1, 1.0/2048).crop(2, 2)\n",
    "\n",
    "p_H1 = data_H1.psd(2)\n",
    "p_H1 = interpolate(p_H1, data_H1.delta_f)\n",
    "p_H1 = inverse_spectrum_truncation(p_H1, 2 * data_H1.sample_rate, low_frequency_cutoff=15.0)\n",
    "psd_H1 = p_H1\n",
    "\n",
    "data_L1 = resample_to_delta_t(ts_L1, 1.0/2048).crop(2, 2)\n",
    "\n",
    "p_L1 = data_L1.psd(2)\n",
    "p_L1 = interpolate(p_L1, data_L1.delta_f)\n",
    "p_L1 = inverse_spectrum_truncation(p_L1, 2 * data_L1.sample_rate, low_frequency_cutoff=15.0)\n",
    "psd_L1 = p_L1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masses=[]\n",
    "import tensorflow as tf\n",
    "\n",
    "for x in range(10,12):\n",
    "  print(x)\n",
    "  from pycbc.waveform import get_td_waveform\n",
    "  hp1, hc1 = get_td_waveform(approximant=\"SEOBNRv4_opt\",\n",
    "                      mass1=x,\n",
    "                      mass2=x,\n",
    "                      delta_t=data_H1.delta_t,\n",
    "                      f_lower=20)\n",
    "\n",
    "  # We will resize the vector to match our data\n",
    "  hp1.resize(len(data_H1))\n",
    "  template1 = hp1.cyclic_time_shift(hp1.start_time)\n",
    "  from pycbc.filter import matched_filter\n",
    "  import numpy\n",
    "\n",
    "  snr1 = matched_filter(template1, data_H1,\n",
    "                      psd=psd_H1, low_frequency_cutoff=20)\n",
    "\n",
    "\n",
    "  snr1 = snr1.crop(4 + 4, 4)\n",
    "\n",
    "\n",
    "  peak1 = abs(snr1).numpy().argmax()\n",
    "  snrp1 = snr1[peak1]\n",
    "  time1 = snr1.sample_times[peak1]\n",
    "\n",
    "  print(\"We found a possible signal candidate at {}s with SNR {} in H1\".format(time1, \n",
    "                                                      abs(snrp1)))\n",
    "  hp2, hc2 = get_td_waveform(approximant=\"SEOBNRv4_opt\",\n",
    "                      mass1=x,\n",
    "                      mass2=x,\n",
    "                      delta_t=data_L1.delta_t,\n",
    "                      f_lower=20)\n",
    "\n",
    "  # We will resize the vector to match our data\n",
    "  hp2.resize(len(data_L1))\n",
    "  template2 = hp2.cyclic_time_shift(hp2.start_time)\n",
    "\n",
    "  snr2 = matched_filter(template2, data_L1,\n",
    "                      psd=psd_L1, low_frequency_cutoff=20)\n",
    "\n",
    "\n",
    "  snr2 = snr2.crop(4 + 4, 4)\n",
    "\n",
    "  peak2 = abs(snr2).numpy().argmax()\n",
    "  snrp2 = snr2[peak2]\n",
    "  time2 = snr2.sample_times[peak2]\n",
    "\n",
    "  print(\"We found a possible signal candidate at {}s with SNR {} in L1\".format(time2, \n",
    "                                                      abs(snrp2)))\n",
    "  if time1==time2:\n",
    "    print(\"Peak Time is coincident in both detectors\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    from pycbc.vetoes import power_chisq\n",
    "\n",
    "    #chisq = {}\n",
    "\n",
    "    nbins = 26\n",
    "    chisq_H1 = power_chisq(hp1, data_H1, nbins, psd_H1, low_frequency_cutoff=20.0)\n",
    "    chisq_H1 = chisq_H1.crop(4 + 4, 4)\n",
    "    \n",
    "    dof = nbins * 2 - 2\n",
    "    chisq_H1 /= dof\n",
    "    \n",
    "    chisq_L1 = power_chisq(hp2, data_L1, nbins, psd_L1, low_frequency_cutoff=20.0)\n",
    "    chisq_L1 = chisq_L1.crop(4 + 4, 4)\n",
    "    \n",
    "    dof = nbins * 2 - 2\n",
    "    chisq_L1 /= dof\n",
    "    \n",
    "    from pycbc.events.ranking import newsnr\n",
    "\n",
    "    nsnr1 = newsnr(abs(snr1), chisq_H1)\n",
    "    nsnr2 = newsnr(abs(snr2), chisq_L1)\n",
    "    \n",
    "    \n",
    "    peak_H1 = nsnr1.argmax()\n",
    "    snrp_H1 = nsnr1[peak_H1]\n",
    "    time_H1 = snr1.sample_times[peak_H1]\n",
    "    print(\"For the Hanford data we found a signal at {}s with SNR {} after ruling out the other candidates as glitches\".format(time_H1, \n",
    "                                                    abs(snrp_H1)))\n",
    "    \n",
    "    peak_L1 = nsnr2.argmax()\n",
    "    snrp_L1 = nsnr2[peak_L1]\n",
    "    time_L1 = snr2.sample_times[peak_L1]\n",
    "    print(\"For the Livingston data we found a signal at {}s with SNR {} after ruling out the other candidates as glitches\".format(time_L1, \n",
    "                                                    abs(snrp_L1)))\n",
    "    \n",
    "    masses.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "massac=[]\n",
    "import tensorflow as tf\n",
    "\n",
    "for x in range(10,12):\n",
    "  print(x)\n",
    "  from pycbc.waveform import get_td_waveform\n",
    "  hp1, hc1 = get_td_waveform(approximant=\"SEOBNRv4_opt\",\n",
    "                      mass1=x,\n",
    "                      mass2=x,\n",
    "                      delta_t=data_H1.delta_t,\n",
    "                      f_lower=20)\n",
    "\n",
    "  # We will resize the vector to match our data\n",
    "  hp1.resize(len(data_H1))\n",
    "  template1 = hp1.cyclic_time_shift(hp1.start_time)\n",
    "  from pycbc.filter import matched_filter\n",
    "  import numpy\n",
    "\n",
    "  snr1 = matched_filter(template1, data_H1,\n",
    "                      psd=psd_H1, low_frequency_cutoff=20)\n",
    "\n",
    "\n",
    "  snr1 = snr1.crop(4 + 4, 4)\n",
    "\n",
    "\n",
    "  peak1 = abs(snr1).numpy().argmax()\n",
    "  snrp1 = snr1[peak1]\n",
    "  time1 = snr1.sample_times[peak1]\n",
    "\n",
    "  print(\"We found a possible signal candidate at {}s with SNR {} in H1\".format(time1, \n",
    "                                                      abs(snrp1)))\n",
    "  hp2, hc2 = get_td_waveform(approximant=\"SEOBNRv4_opt\",\n",
    "                      mass1=x,\n",
    "                      mass2=x,\n",
    "                      delta_t=data_L1.delta_t,\n",
    "                      f_lower=20)\n",
    "\n",
    "  # We will resize the vector to match our data\n",
    "  hp2.resize(len(data_L1))\n",
    "  template2 = hp2.cyclic_time_shift(hp2.start_time)\n",
    "\n",
    "  snr2 = matched_filter(template2, data_L1,\n",
    "                      psd=psd_L1, low_frequency_cutoff=20)\n",
    "\n",
    "\n",
    "  snr2 = snr2.crop(4 + 4, 4)\n",
    "\n",
    "  peak2 = abs(snr2).numpy().argmax()\n",
    "  snrp2 = snr2[peak2]\n",
    "  time2 = snr2.sample_times[peak2]\n",
    "\n",
    "  print(\"We found a possible signal candidate at {}s with SNR {} in L1\".format(time2, \n",
    "                                                      abs(snrp2)))\n",
    "  if time1==time2:\n",
    "    print(\"Peak Time is coincident in both detectors\")\n",
    "    from pycbc.filter import sigma\n",
    "    dt1 = time1 - data_H1.start_time\n",
    "    aligned1 = template1.cyclic_time_shift(dt1)\n",
    "\n",
    "    # scale the template so that it would have SNR 1 in this data\n",
    "    aligned1 /= sigma(aligned1, psd=psd_H1, low_frequency_cutoff=20.0)\n",
    "\n",
    "    # Scale the template amplitude and phase to the peak value\n",
    "    aligned1 = (aligned1.to_frequencyseries() * snrp1).to_timeseries()\n",
    "    aligned1.start_time = data_H1.start_time\n",
    "    # We do it this way so that we can whiten both the template and the data\n",
    "    white_data1 = (data_H1.to_frequencyseries() / psd_H1**0.5).to_timeseries()\n",
    "\n",
    "    # apply a smoothing of the turnon of the template to avoid a transient\n",
    "    # from the sharp turn on in the waveform.\n",
    "    tapered1 = aligned1.highpass_fir(30, 512, remove_corrupted=False)\n",
    "    white_template1 = (tapered1.to_frequencyseries() / psd_H1**0.5).to_timeseries()\n",
    "\n",
    "    white_data1 = white_data1.highpass_fir(30., 512).lowpass_fir(300, 512)\n",
    "    white_template1 = white_template1.highpass_fir(30, 512).lowpass_fir(300, 512)\n",
    "\n",
    "    # Select the time around the merger\n",
    "    white_data1 = white_data1.time_slice(time1-0.2, time1+.10)\n",
    "    white_template1 = white_template1.time_slice(time1-0.2, time1+.10)\n",
    "    dt2 = time2 - data_L1.start_time\n",
    "    aligned2 = template2.cyclic_time_shift(dt2)\n",
    "\n",
    "    # scale the template so that it would have SNR 2 in this data\n",
    "    aligned2 /= sigma(aligned2, psd=psd_L1, low_frequency_cutoff=20.0)\n",
    "\n",
    "    # Scale the template amplitude and phase to the peak value\n",
    "    aligned2 = (aligned2.to_frequencyseries() * snrp2).to_timeseries()\n",
    "    aligned2.start_time = data_L1.start_time\n",
    "    # We do it this way so that we can whiten both the template and the data\n",
    "    white_data2 = (data_L1.to_frequencyseries() / psd_L1**0.5).to_timeseries()\n",
    "\n",
    "    # apply a smoothing of the turnon of the template to avoid a transient\n",
    "    # from the sharp turn on in the waveform.\n",
    "    tapered2 = aligned2.highpass_fir(30, 512, remove_corrupted=False)\n",
    "    white_template2 = (tapered2.to_frequencyseries() / psd_L1**0.5).to_timeseries()\n",
    "\n",
    "    white_data2 = white_data2.highpass_fir(30., 512).lowpass_fir(300, 512)\n",
    "    white_template2 = white_template2.highpass_fir(30, 512).lowpass_fir(300, 512)\n",
    "\n",
    "    # Select the time around the merger\n",
    "    white_data2 = white_data2.time_slice(time2-0.2, time2+.10)\n",
    "    white_template2 = white_template2.time_slice(time2-0.2, time2+.10)\n",
    "    print('and mean abs error='+str(tf.keras.metrics.mean_absolute_error(white_data1,white_template1).numpy())+','+str(tf.keras.metrics.mean_absolute_error(white_data2,white_template2).numpy()))\n",
    "\n",
    "    massac.append(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "dV5z8gFjslpG"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "17:48 bilby INFO    : Reading data from frame file challenge3.gwf\n",
      "17:48 bilby INFO    : Successfully loaded H1:CHALLENGE3.\n",
      "17:48 bilby INFO    : Reading data from frame file challenge3.gwf\n",
      "17:48 bilby INFO    : Successfully loaded L1:CHALLENGE3.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division, print_function\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import bilby\n",
    "from bilby.core.prior import Uniform\n",
    "from bilby.gw.conversion import convert_to_lal_binary_black_hole_parameters, generate_all_bbh_parameters\n",
    "\n",
    "from gwpy.timeseries import TimeSeries\n",
    "\n",
    "sampling_rate=2048 #needs to be high enough for the signals found in steps above\n",
    "duration=8 #needs to be long enough for the signals found in steps above\n",
    "start_time=100 #needs to be set so that the segment defined by [start_time,start_time+duration] contains the signal\n",
    "\n",
    "interferometers = bilby.gw.detector.InterferometerList([])\n",
    "for ifo_name in ['H1','L1']:\n",
    "    ifo=bilby.gw.detector.get_empty_interferometer(ifo_name)\n",
    "    ifo.set_strain_data_from_frame_file('challenge3.gwf',sampling_rate, duration, start_time=start_time ,channel=ifo_name+':CHALLENGE3')\n",
    "    interferometers.append(ifo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "task4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
